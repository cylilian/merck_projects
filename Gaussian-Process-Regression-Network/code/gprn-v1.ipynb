{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from scipy.special import logsumexp\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPRN_model(torch.nn.Module):\n",
    "    def __init__(self, kernel, P, Q, N, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        print('Initialize GPRN model')\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.N = N\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # f, w kernel\n",
    "        if kernel == 'rbf':\n",
    "            self.kernel_f = utils.Kernel_RBF().to(self.device)\n",
    "            self.kernel_w = utils.Kernel_RBF().to(self.device)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        # noise variance\n",
    "        self.raw_sigma2_f = torch.nn.Parameter(torch.tensor(0., dtype=self.dtype, device=self.device))\n",
    "        self.raw_sigma2_y = torch.nn.Parameter(torch.tensor(0., dtype=self.dtype, device=self.device))\n",
    "\n",
    "        # intialize variational parameters\n",
    "        self.f_mu = torch.nn.Parameter(torch.randn(self.Q, self.N, dtype=self.dtype, device=self.device))\n",
    "        self.f_raw_sigma2 = torch.nn.Parameter(torch.zeros(self.Q, self.N, dtype=self.dtype, device=self.device))\n",
    "        self.w_mu = torch.nn.Parameter(torch.randn(self.P, self.Q, self.N, dtype=self.dtype, device=self.device))\n",
    "        self.w_raw_sigma2 = torch.nn.Parameter(\n",
    "            torch.randn(self.P, self.Q, self.N, dtype=self.dtype, device=self.device))\n",
    "\n",
    "    def loss(self, X, Y):\n",
    "        sigma2_y = torch.exp(self.raw_sigma2_y)\n",
    "        sigma2_f = torch.exp(self.raw_sigma2_f)\n",
    "        f_sigma2 = torch.exp(self.f_raw_sigma2) # Q x N\n",
    "        w_sigma2 = torch.exp(self.w_raw_sigma2) # P x Q x N\n",
    "        f_mu = self.f_mu.transpose(1,0) # N x Q\n",
    "        f_mu_expand = f_mu[..., None] # N x Q x 1\n",
    "        w_mu = self.w_mu.permute(2,0,1) # N x P x Q\n",
    "        # compute expectation of conditional log likelihood\n",
    "        diff = Y - torch.matmul(w_mu, f_mu_expand).squeeze()           #shape: N x P\n",
    "        w_mu2 = w_mu ** 2 # N x P x Q\n",
    "        f_mu2 = f_mu_expand ** 2 # N x Q x 1\n",
    "        f_sigma2_expand = torch.unsqueeze(f_sigma2, 0).expand(self.P, -1, -1)     # shape P x Q x N\n",
    "        f_mu2_expand = f_mu2.expand(-1, -1, self.P) # shape N x Q x P\n",
    "        exp_llik = -0.5*self.N*self.P*torch.log(2*np.pi*sigma2_y) - 0.5/sigma2_y*torch.sum(diff**2) - \\\n",
    "                   0.5/sigma2_y*((w_mu2.permute(1,2,0)*f_sigma2_expand).sum() + (w_sigma2*f_mu2_expand.permute(2,1,0)).sum())\n",
    "        # compute expectation of log joint probability of latent variables\n",
    "        K_f = self.kernel_f(X, X) + sigma2_f*torch.eye(self.N).to(self.device)\n",
    "        chol_K_f = utils.psd_cholesky(K_f, device=self.device)\n",
    "        inv_K_f = utils.psd_inv(K_f, device=self.device)\n",
    "        scaled_f_mu = torch.triangular_solve(f_mu, chol_K_f, upper=False)[0]\n",
    "        K_w = self.kernel_w(X, X)\n",
    "        chol_K_w = utils.psd_cholesky(K_w, device=self.device)\n",
    "        inv_K_w = utils.psd_inv(K_w, device=self.device)\n",
    "        scaled_w_mu = torch.triangular_solve(self.w_mu[..., None], chol_K_w, upper=False)[0].squeeze() # P x Q x N\n",
    "        exp_jlp = -0.5*(self.Q*torch.logdet(K_f) + torch.sum(scaled_f_mu**2) + torch.matmul(f_sigma2,\n",
    "                    torch.diag(inv_K_f)).sum()) - 0.5 * (self.P*self.Q*torch.logdet(K_w) + torch.sum(scaled_w_mu**2) +\n",
    "                    torch.matmul(w_sigma2, torch.diag(inv_K_w)).sum())\n",
    "        # compute entropies\n",
    "        H = 0.5*self.f_raw_sigma2.sum() + 0.5*self.w_raw_sigma2.sum()\n",
    "\n",
    "        elbo = exp_llik + exp_jlp + H\n",
    "\n",
    "        # print(exp_llik, exp_jlp, H)\n",
    "\n",
    "        return -elbo\n",
    "\n",
    "    def predict(self, X_train, X):\n",
    "        sigma2_f = torch.exp(self.raw_sigma2_f)\n",
    "\n",
    "        Kw11 = self.kernel_w(X_train, X_train) # N x N\n",
    "        Kw12 = self.kernel_w(X_train, X) # N x M\n",
    "        Kw11InvKw12 = torch.solve(A=Kw11, input=Kw12)[0] # N x M\n",
    "        W_p = torch.matmul(torch.unsqueeze(self.w_mu, dim=-2), Kw11InvKw12[None,None,...]).squeeze() # P x Q x M\n",
    "        Kf11 = self.kernel_f(X_train, X_train) + sigma2_f*torch.eye(self.N).to(self.device) # N x N\n",
    "        Kf12 = self.kernel_f(X_train, X)  # N x M\n",
    "        Kf11InvKf12 = torch.solve(A=Kf11, input=Kf12)[0]  # N x M\n",
    "        f_p = torch.matmul(torch.unsqueeze(self.f_mu, dim=-2), Kf11InvKf12[None,None,...]).squeeze() # Q x M\n",
    "        Y_p = torch.matmul(W_p.permute(2,0,1), f_p.permute(1,0)[..., None]).squeeze() # M P\n",
    "        return Y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPRN(torch.nn.Module):\n",
    "    def __init__(self, config, device='cpu', dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        print('Initialize GPRN')\n",
    "\n",
    "        self.config = config\n",
    "        self.Q = self.config['Q']\n",
    "        self.in_d = self.config['data']['X_train'].shape[1]\n",
    "        self.out_d = self.config['data']['Y_train'].shape[1]\n",
    "        self.jitter = config['jitter']\n",
    "        self.kernel = self.config['kernel']\n",
    "        self.device = device\n",
    "        self.dtype=dtype\n",
    "\n",
    "        self.X_train = self.config['data']['X_train'].reshape((-1, self.in_d))\n",
    "        self.X_test = self.config['data']['X_test'].reshape((-1, self.in_d))\n",
    "        self.Y_train = self.config['data']['Y_train'].reshape((-1, self.out_d))\n",
    "        self.Y_test = self.config['data']['Y_test'].reshape((-1, self.out_d))\n",
    "        self.Y_test_ground = self.config['data']['Y_test_ground'].reshape((-1, self.out_d))\n",
    "        self.Y_mean = self.config['data']['Y_mean']\n",
    "        self.Y_std = self.config['data']['Y_std']\n",
    "\n",
    "        self.epochs = config['epochs']\n",
    "        self.lr = config['lr']\n",
    "\n",
    "        self.record_time = config['record_time']\n",
    "\n",
    "        self.M = self.X_test.shape[0]\n",
    "        self.N = self.X_train.shape[0]\n",
    "        self.P = self.out_d\n",
    "        self.model = GPRN_model(self.kernel, self.P, self.Q, self.N, dtype=self.dtype, device=self.device)\n",
    "\n",
    "    def fit(self, epochs=None):\n",
    "        if epochs is None:\n",
    "            epochs = self.epochs\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        res = dict()\n",
    "        loss_list = list()\n",
    "        hist_pred = list()\n",
    "        # hist_nrmse = list()\n",
    "        # hist_nmae = list()\n",
    "        X_train = torch.from_numpy(self.X_train).to(self.device)\n",
    "        Y_train = torch.from_numpy(self.Y_train).to(self.device)\n",
    "        X_test = torch.from_numpy(self.X_test).to(self.device)\n",
    "        Y_test_ground = torch.from_numpy(self.Y_test_ground).to(self.device)\n",
    "        Y_mean = torch.from_numpy(self.Y_mean).to(self.device)\n",
    "        Y_std = torch.from_numpy(self.Y_std).to(self.device)\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.model.loss(X_train, Y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred_Y = self.model.predict(X_train, X_test) * Y_std + Y_mean\n",
    "            # r0 = torch.sqrt(torch.mean((pred_Y - Y_test_ground)**2)) / torch.std(Y_test_ground)\n",
    "            # r1 = torch.mean(torch.abss(pred_Y - Y_test_ground)) / torch.std(Y_test_ground)\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"epoch {}, loss: {}.\".format(epoch, loss))\n",
    "            loss_list.append(loss.item())\n",
    "            hist_pred.append(pred_Y.to('cpu').detach().numpy())\n",
    "\n",
    "        res['loss'] = loss_list\n",
    "        res['Y_pred'] = hist_pred\n",
    "        # breakpoint()\n",
    "        return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-gp-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
