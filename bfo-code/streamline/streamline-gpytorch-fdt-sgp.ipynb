{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pandas import factorize\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "import gpytorch\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m3gpr.config import get_cfg_defaults_all\n",
    "from m3gpr.load_data import Data_set\n",
    "from m3gpr.models import singleGP_gpytorch,rf_sklearn,singleGP_gpytorch_train,singleGP_gpytorch_reference,MultitaskGPModel,MTMOGP\n",
    "from m3gpr.train import CV_Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singleGP\n",
      "y-stand\n",
      "(454, 55)\n",
      "(454, 5)\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg_defaults_all()\n",
    "os.chdir('/Users/chenya68/Documents/GitHub/BFO')\n",
    "parser = argparse.ArgumentParser(description=\"Configure files\")\n",
    "parser.add_argument(\"--cfg\", required=True, help=\"path to config file\", type=str)\n",
    "#args = parser.parse_args(['--cfg', 'data/harpoon/harpoon_dataset.yaml'])\n",
    "args = parser.parse_args(['--cfg', 'bfo-data/fdt_data/fdt_dataset.yaml'])\n",
    "cfg.merge_from_file(args.cfg)\n",
    "\n",
    "cfg.freeze()\n",
    "setup_data = Data_set(cfg, 1)\n",
    "print(cfg.MODEL.MODEL_NAME)\n",
    "print(cfg.MODEL.Y_SCALE)\n",
    "\n",
    "#df_x, df_y_wide, df_y_long = setup_data.Load_data_set()\n",
    "df_x, df_y,ls_X_train,ls_X_test,ls_y_train,ls_y_test, obj_y_scaler= setup_data.Load_data_set()\n",
    "print(df_x.shape)\n",
    "print(df_y.shape)\n",
    "#print(df_y_wide.shape)\n",
    "#print(df_y_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        HARDNESS  FRIABILITY  Drug_content  \\\n",
      "HARDNESS                1.000000    0.091377      0.048112   \n",
      "FRIABILITY              0.091377    1.000000      0.053990   \n",
      "Drug_content            0.048112    0.053990      1.000000   \n",
      "Water_absorption_ratio  0.003404    0.041980     -0.005044   \n",
      "DISINTEGRATION_TIME    -0.095159   -0.108785     -0.065873   \n",
      "\n",
      "                        Water_absorption_ratio  DISINTEGRATION_TIME  \n",
      "HARDNESS                              0.003404            -0.095159  \n",
      "FRIABILITY                            0.041980            -0.108785  \n",
      "Drug_content                         -0.005044            -0.065873  \n",
      "Water_absorption_ratio                1.000000            -0.183772  \n",
      "DISINTEGRATION_TIME                  -0.183772             1.000000  \n"
     ]
    }
   ],
   "source": [
    "df_y_corr = df_y.corr()\n",
    "df_y_corr.to_csv(cfg.PATH.DATA_PATH + 'df_y_corr.csv')\n",
    "print(df_y_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      " Parameter containing:\n",
      "tensor([[ 9.9152e-01,  2.6691e-02,  2.3423e+00,  1.4601e-01, -3.4544e+00],\n",
      "        [ 2.6691e-02,  8.6049e-02,  7.7433e-01,  5.3046e-01, -1.1634e+00],\n",
      "        [ 2.3423e+00,  7.7433e-01,  2.3904e+03, -1.0624e+01, -1.1741e+02],\n",
      "        [ 1.4601e-01,  5.3046e-01, -1.0624e+01,  1.8556e+03, -2.8860e+02],\n",
      "        [-3.4544e+00, -1.1634e+00, -1.1741e+02, -2.8860e+02,  1.3290e+03]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def correlation_to_covariance(corr_matrix, std_devs):\n",
    "    \"\"\"\n",
    "    Convert a correlation matrix to a covariance matrix.\n",
    "\n",
    "    Parameters:\n",
    "        corr_matrix (np.ndarray): Square correlation matrix (n x n).\n",
    "        std_devs (np.ndarray): 1D array of standard deviations (length n).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Covariance matrix (n x n).\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    corr_matrix = np.array(corr_matrix, dtype=float)\n",
    "    std_devs = np.array(std_devs, dtype=float)\n",
    "\n",
    "    if corr_matrix.shape[0] != corr_matrix.shape[1]:\n",
    "        raise ValueError(\"Correlation matrix must be square.\")\n",
    "    if corr_matrix.shape[0] != std_devs.shape[0]:\n",
    "        raise ValueError(\"Length of std_devs must match matrix size.\")\n",
    "    if not np.allclose(corr_matrix, corr_matrix.T, atol=1e-8):\n",
    "        raise ValueError(\"Correlation matrix must be symmetric.\")\n",
    "    if np.any(np.diag(corr_matrix) != 1):\n",
    "        raise ValueError(\"Diagonal elements of correlation matrix must be 1.\")\n",
    "\n",
    "    # Create diagonal matrix of standard deviations\n",
    "    D = np.diag(std_devs)\n",
    "\n",
    "    # Covariance = D * Corr * D\n",
    "    cov_matrix = D @ corr_matrix @ D\n",
    "    return cov_matrix\n",
    "\n",
    "\n",
    "# Example usage\n",
    "corr = df_y_corr.values\n",
    "std_devs = df_y.std().to_list()\n",
    "\n",
    "cov = correlation_to_covariance(corr, std_devs)\n",
    "cov = torch.nn.Parameter(torch.Tensor(cov))\n",
    "print(\"Covariance Matrix:\\n\", cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single GP Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "\n",
    "        model_name = cfg.MODEL.MODEL_NAME\n",
    "        n_cv = cfg.MODEL.N_CV#cfg.MODEL.N_CV is number of cv\n",
    "        num_outputs = cfg.DATA.NUM_OUTPUTS\n",
    "        if cfg.MODEL.SPLIT == 'by-task':\n",
    "            num_tasks = cfg.DATA.NUM_TASKS\n",
    "        else:\n",
    "            num_tasks = 1\n",
    "        num_total_output = num_outputs*num_tasks\n",
    "        num_cols = num_total_output*n_cv\n",
    "        y_scale=cfg.MODEL.Y_SCALE\n",
    "        metric_row = 3\n",
    "\n",
    "        \n",
    "        ls_model_from_combs = [[] for _ in range(num_total_output)]\n",
    "        ls_init_len = [2.0,3.0,4.0]\n",
    "        ls_lr = [0.1,0.15,0.2,0.25]\n",
    "        ls_n_iter = [200,300]\n",
    "        combs = list(itertools.product(ls_init_len,ls_lr,ls_n_iter))\n",
    "\n",
    "        mean_arr_cv_mae = np.zeros((2,len(combs))) #train,test\n",
    "        mean_arr_cv_r2 = np.zeros((2,len(combs))) #train,test\n",
    "        mean_arr_cv_err = np.zeros((2,len(combs))) #train,test\n",
    "\n",
    "        ls_arr_cv_mae = [np.zeros((2,len(combs))) for _ in range(num_total_output)]\n",
    "        ls_arr_cv_r2 = [np.zeros((2,len(combs))) for _ in range(num_total_output)]\n",
    "        ls_arr_cv_err = [np.zeros((2,len(combs))) for _ in range(num_total_output)]\n",
    "\n",
    "        \n",
    "        for i in range(0,len(combs)):\n",
    "            init_len,lr,n_iter = combs[i]\n",
    "            arr_train_metrics = np.zeros((11,num_cols))\n",
    "            arr_test_metrics = np.zeros((11,num_cols))\n",
    "            \n",
    "            for batch_ind in range(n_cv):\n",
    "                t_train_x = ls_X_train[batch_ind]\n",
    "                t_test_x = ls_X_test[batch_ind]\n",
    "                \n",
    "                #for j in range(self.num_outputs):\n",
    "                for j in range(num_total_output):\n",
    "                    a = batch_ind + n_cv*j\n",
    "                    t_train_y = ls_y_train[batch_ind][:,j].flatten()\n",
    "                    t_test_y = ls_y_test[batch_ind][:,j].flatten()\n",
    "\n",
    "                    train_mean,train_lower,train_upper,model = singleGP_gpytorch_train(t_train_x,t_train_y,training_iter = n_iter,init_len_scale = init_len,my_lr = lr)\n",
    "                    #print(train_mean)\n",
    "                    ls_model_from_combs[j].append(model)\n",
    "                    \n",
    "                    # Set into eval mode\n",
    "                    model.eval()\n",
    "                    model.likelihood.eval()\n",
    "\n",
    "                    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                        test_pred = model.likelihood(model(t_test_x))   \n",
    "                        test_mean = test_pred.mean\n",
    "                        test_lower, test_upper = test_pred.confidence_region()\n",
    "\n",
    "                    if y_scale=='no-y-scale':\n",
    "                        arr_train_y = t_train_y.detach().numpy()\n",
    "                        arr_test_y = t_test_y.detach().numpy()\n",
    "                        arr_test_mean = test_mean.detach().numpy()\n",
    "                        arr_test_lower = test_lower.detach().numpy()\n",
    "                        arr_test_upper = test_upper.detach().numpy()\n",
    "\n",
    "                        arr_train_mean = train_mean.detach().numpy()\n",
    "                        arr_train_lower = train_lower.detach().numpy()\n",
    "                        arr_train_upper = train_upper.detach().numpy()\n",
    "                    else:\n",
    "                        y_scaler = obj_y_scaler[batch_ind]\n",
    "                        tmp_mean = y_scaler.mean_\n",
    "                        tmp_scale = y_scaler.scale_\n",
    "\n",
    "                        arr_train_y = t_train_y.detach().numpy()\n",
    "                        arr_test_y = t_test_y.detach().numpy()\n",
    "                        arr_test_mean = test_mean.detach().numpy()\n",
    "                        arr_test_lower = test_lower.detach().numpy()\n",
    "                        arr_train_mean = train_mean.detach().numpy()\n",
    "                        arr_train_lower = train_lower.detach().numpy()\n",
    "\n",
    "                        arr_train_y = arr_train_y*tmp_scale[j] + tmp_mean[j]\n",
    "                        arr_test_mean = arr_test_mean*tmp_scale[j] + tmp_mean[j]\n",
    "                        arr_test_lower = arr_test_lower*tmp_scale[j] + tmp_mean[j]\n",
    "                        arr_train_mean = arr_train_mean*tmp_scale[j] + tmp_mean[j]\n",
    "                        arr_train_lower = arr_train_lower*tmp_scale[j] + tmp_mean[j]\n",
    "\n",
    "                    y_true = arr_test_y\n",
    "                    y_pred = arr_test_mean\n",
    "                    y_train = arr_train_y\n",
    "                    mean_train = arr_train_mean\n",
    "                    std_train = arr_train_mean - arr_train_lower\n",
    "                    std_test = arr_test_mean - arr_test_lower\n",
    "\n",
    "                    train_comp = np.concatenate((y_train.reshape(-1,1),mean_train.reshape(-1,1)),axis = 1)\n",
    "                    df_train_comp = pd.DataFrame(train_comp,columns = ['true','pred'])\n",
    "                    df_train_comp['upper'] = df_train_comp['pred'] + std_train.squeeze()\n",
    "                    df_train_comp['lower'] = df_train_comp['pred'] - std_train.squeeze()\n",
    "                    df_train_comp['mode'] = 'train'\n",
    "    \n",
    "                    test_comp = np.concatenate((y_true.reshape(-1,1),y_pred.reshape(-1,1)),axis = 1)\n",
    "                    df_test_comp = pd.DataFrame(test_comp,columns = ['true','pred'])\n",
    "                    df_test_comp['upper'] = df_test_comp['pred'] + std_test.squeeze()\n",
    "                    df_test_comp['lower'] = df_test_comp['pred'] - std_test.squeeze()\n",
    "                    df_test_comp['mode'] = 'test'\n",
    "    \n",
    "\n",
    "                    arr_test_metrics[0,a] = metrics.mean_absolute_error(y_true, y_pred)\n",
    "                    arr_test_metrics[1,a] = metrics.median_absolute_error(y_true, y_pred)\n",
    "                    arr_test_metrics[2,a] = metrics.mean_squared_error(y_true, y_pred)\n",
    "                    arr_test_metrics[3,a] = metrics.root_mean_squared_error(y_true, y_pred)\n",
    "                    arr_test_metrics[4,a] = metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "                    arr_test_metrics[5,a] = metrics.max_error(y_true, y_pred)\n",
    "                    arr_test_metrics[6,a] = metrics.explained_variance_score(y_true, y_pred)\n",
    "                    arr_test_metrics[7,a] = metrics.r2_score(y_true, y_pred)\n",
    "                    arr_test_metrics[8,a] = np.mean(std_test)\n",
    "                    arr_test_metrics[9,a] = np.min(std_test)\n",
    "                    arr_test_metrics[10,a] = np.max(std_test)\n",
    "\n",
    "                    arr_train_metrics[0,a] = metrics.mean_absolute_error(y_train, mean_train)\n",
    "                    arr_train_metrics[1,a] = metrics.median_absolute_error(y_train, mean_train)\n",
    "                    arr_train_metrics[2,a] = metrics.mean_squared_error(y_train, mean_train)\n",
    "                    arr_train_metrics[3,a] = metrics.root_mean_squared_error(y_train, mean_train)\n",
    "                    arr_train_metrics[4,a] = metrics.mean_absolute_percentage_error(y_train, mean_train)\n",
    "                    arr_train_metrics[5,a] = metrics.max_error(y_train, mean_train)\n",
    "                    arr_train_metrics[6,a] = metrics.explained_variance_score(y_train, mean_train)\n",
    "                    arr_train_metrics[7,a] = metrics.r2_score(y_train, mean_train)\n",
    "                    arr_train_metrics[8,a] = np.mean(std_train)\n",
    "                    arr_train_metrics[9,a] = np.min(std_train)\n",
    "                    arr_train_metrics[10,a] = np.max(std_train)\n",
    "                    arr_train_metrics[8,a] = np.mean(std_train)\n",
    "                    arr_train_metrics[9,a] = np.min(std_train)\n",
    "                    arr_train_metrics[10,a] = np.max(std_train)\n",
    "      \n",
    "                    ls_arr_cv_mae[j][0,i] = np.mean(arr_train_metrics[metric_row,n_cv*j:n_cv*(j+1)])\n",
    "                    ls_arr_cv_mae[j][1,i] = np.mean(arr_test_metrics[metric_row,n_cv*j:n_cv*(j+1)])\n",
    "\n",
    "                    ls_arr_cv_r2[j][0,i] = np.mean(arr_train_metrics[6,n_cv*j:n_cv*(j+1)])\n",
    "                    ls_arr_cv_r2[j][1,i] = np.mean(arr_test_metrics[6,n_cv*j:n_cv*(j+1)])\n",
    "\n",
    "                    ls_arr_cv_err[j][0,i] = np.mean(arr_train_metrics[8,n_cv*j:n_cv*(j+1)])\n",
    "                    ls_arr_cv_err[j][1,i] = np.mean(arr_test_metrics[8,n_cv*j:n_cv*(j+1)])\n",
    "\n",
    "            mean_arr_cv_mae[0,i] = np.mean(arr_train_metrics[metric_row,:])\n",
    "            mean_arr_cv_mae[1,i] = np.mean(arr_test_metrics[metric_row,:])\n",
    "\n",
    "            mean_arr_cv_r2[0,i] = np.mean(arr_train_metrics[6,:])\n",
    "            mean_arr_cv_r2[1,i] = np.mean(arr_test_metrics[6,:])\n",
    "\n",
    "            mean_arr_cv_err[0,i] = np.mean(arr_train_metrics[8,:])\n",
    "            mean_arr_cv_err[1,i] = np.mean(arr_test_metrics[8,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    sgp_cv_trainer = CV_Trainer(cfg,ls_X_train,ls_X_test,ls_y_train,ls_y_test,obj_y_scaler,cov)\n",
    "    combs,ls_model_from_combs,ls_arr_cv_mae,ls_arr_cv_r2,ls_arr_cv_err,mean_arr_cv_mae,mean_arr_cv_r2,mean_arr_cv_err = sgp_cv_trainer.set_up_sgp_cv()\n",
    "    \n",
    "    if cfg.MODEL.SPLIT == 'by-task':\n",
    "        num_tasks = cfg.DATA.NUM_TASKS\n",
    "    else:\n",
    "        num_tasks = 1\n",
    "    \n",
    "    #num_tasks = cfg.DATA.NUM_TASKS\n",
    "    num_outputs = cfg.DATA.NUM_OUTPUTS\n",
    "    num_total_outputs = num_outputs*num_tasks\n",
    "    arr_metrics = np.zeros((3,1+num_total_outputs)) #row:mae, r2, avg_std; col: total mean, task1(output1), task2(output2),...\n",
    "\n",
    "    print('number of tasks that are being compared: ',num_total_outputs)\n",
    "\n",
    "    best_idx = np.argmin(mean_arr_cv_mae[1,:])\n",
    "    #best_idx = np.argmax(mean_arr_cv_r2[1,:])\n",
    "\n",
    "    print('best_idx',best_idx)\n",
    "    print('best combinations: ',combs[best_idx])\n",
    "\n",
    "    arr_metrics[0,0] = np.min(mean_arr_cv_mae[1,:])\n",
    "    arr_metrics[1,0] = np.max(mean_arr_cv_r2[1,:])\n",
    "    arr_metrics[2,0] = mean_arr_cv_err[1,best_idx]\n",
    "\n",
    "    print('best mean mae %.3f' % arr_metrics[0,0])\n",
    "    print('best mean r2 %.3f' % arr_metrics[1,0])\n",
    "    print('best mean err %.3f' % arr_metrics[2,0])\n",
    "    \n",
    "    cols_target_new = ['total']\n",
    "    for task_ind in range(num_tasks):\n",
    "        for out_ind in range(num_outputs):\n",
    "            j = out_ind + num_outputs*task_ind\n",
    "    #for j in range(num_total_outputs):\n",
    "            j_name = 'Task_'+str(task_ind+1) + '_Output_'+str(out_ind+1)\n",
    "            cols_target_new.append(j_name)\n",
    "            arr_metrics[0,j+1] = ls_arr_cv_mae[j][1,best_idx]\n",
    "            arr_metrics[1,j+1] = ls_arr_cv_r2[j][1,best_idx]\n",
    "            arr_metrics[2,j+1] = ls_arr_cv_err[j][1,best_idx]\n",
    "            print('best mae of target %d is %.3f' %(j,ls_arr_cv_mae[j][1,best_idx]))\n",
    "            print('best r2 of target %d is %.3f' %(j,ls_arr_cv_r2[j][1,best_idx]))\n",
    "            print('best err of target %d is %.3f' % (j,ls_arr_cv_err[j][1,best_idx]))\n",
    "    \n",
    "    df_test_metrics = pd.DataFrame(np.round(arr_metrics,3),columns = cols_target_new, \n",
    "                               index = [cfg.MODEL.METRIC,'R2','AVG_STD'])\n",
    "    print(df_test_metrics)\n",
    "    \n",
    "    #output_path = '/'.join([cfg.PATH.RESULT,cfg.MISC.DATA_NAME,cfg.MODEL.MODEL_NAME,cfg.MODEL.SPLIT,cfg.MISC.DATE])\n",
    "    df_test_metrics.to_csv(setup_data.output_path+'/df_test_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-gp-mac-no-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
