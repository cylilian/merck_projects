{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pandas import factorize\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "import gpytorch\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import m3hgpr\n",
    "from m3hgpr.config import get_cfg_defaults_all\n",
    "from m3hgpr.load_data import Data_set\n",
    "from m3hgpr.models import singleGP_gpytorch,rf_sklearn,singleGP_gpytorch_train,singleGP_gpytorch_reference,MultitaskGPModel,MTMOGP\n",
    "from m3hgpr.train import CV_Trainer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m3gpr.config import get_cfg_defaults_all\n",
    "from m3gpr.load_data import Data_set\n",
    "from m3gpr.models import singleGP_gpytorch,rf_sklearn,singleGP_gpytorch_train,singleGP_gpytorch_reference,MultitaskGPModel,MTMOGP\n",
    "from m3gpr.train import CV_Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder /Users/chenya68/Documents/GitHub/BFO/output/Harpoon/MTMO/by-task/djan2026/num_tasks_2\n",
      "MTMO\n",
      "y-stand\n",
      "ohe\n",
      "(48, 10)\n",
      "(48, 2)\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg_defaults_all()\n",
    "os.chdir('/Users/chenya68/Documents/GitHub/BFO')\n",
    "parser = argparse.ArgumentParser(description=\"Configure files\")\n",
    "parser.add_argument(\"--cfg\", required=True, help=\"path to config file\", type=str)\n",
    "args = parser.parse_args(['--cfg', 'data/harpoon/harpoon_dataset.yaml'])\n",
    "cfg.merge_from_file(args.cfg)\n",
    "\n",
    "cfg.freeze()\n",
    "setup_data = Data_set(cfg, 1)\n",
    "print(cfg.MODEL.MODEL_NAME)\n",
    "print(cfg.MODEL.Y_SCALE)\n",
    "\n",
    "#df_x, df_y_wide, df_y_long = setup_data.Load_data_set()\n",
    "df_x, df_y,ls_X_train,ls_X_test,ls_y_train,ls_y_test, obj_y_scaler= setup_data.Load_data_set()\n",
    "print(df_x.shape)\n",
    "print(df_y.shape)\n",
    "#print(df_y_wide.shape)\n",
    "#print(df_y_long.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single GP Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "number of tasks that are being compared:  6\n",
      "best_idx 16\n",
      "best combinations:  (4.0, 0.1, 200)\n",
      "best mean mae 0.494\n",
      "best mean r2 0.484\n",
      "best mean err 0.919\n",
      "best mae of target 0 is 0.493\n",
      "best r2 of target 0 is 0.668\n",
      "best err of target 0 is 0.955\n",
      "best mae of target 1 is 0.679\n",
      "best r2 of target 1 is 0.384\n",
      "best err of target 1 is 1.163\n",
      "best mae of target 2 is 0.216\n",
      "best r2 of target 2 is 0.415\n",
      "best err of target 2 is 0.382\n",
      "best mae of target 3 is 0.307\n",
      "best r2 of target 3 is 0.214\n",
      "best err of target 3 is 0.540\n",
      "best mae of target 4 is 0.447\n",
      "best r2 of target 4 is 0.771\n",
      "best err of target 4 is 0.924\n",
      "best mae of target 5 is 0.822\n",
      "best r2 of target 5 is 0.452\n",
      "best err of target 5 is 1.549\n",
      "         total  Task_1_Output_1  Task_1_Output_2  Task_2_Output_1  \\\n",
      "RMSE     0.494            0.493            0.679            0.216   \n",
      "R2       0.484            0.668            0.384            0.415   \n",
      "AVG_STD  0.919            0.955            1.163            0.382   \n",
      "\n",
      "         Task_2_Output_2  Task_3_Output_1  Task_3_Output_2  \n",
      "RMSE               0.307            0.447            0.822  \n",
      "R2                 0.214            0.771            0.452  \n",
      "AVG_STD            0.540            0.924            1.549  \n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    sgp_cv_trainer = CV_Trainer(cfg,ls_X_train,ls_X_test,ls_y_train,ls_y_test,obj_y_scaler)\n",
    "    combs,ls_model_from_combs,ls_arr_cv_mae,ls_arr_cv_r2,ls_arr_cv_err,mean_arr_cv_mae,mean_arr_cv_r2,mean_arr_cv_err = sgp_cv_trainer.set_up_sgp_cv()\n",
    "    \n",
    "    if cfg.MODEL.SPLIT == 'by-task':\n",
    "        num_tasks = cfg.DATA.NUM_TASKS\n",
    "    else:\n",
    "        num_tasks = 1\n",
    "    \n",
    "    #num_tasks = cfg.DATA.NUM_TASKS\n",
    "    num_outputs = cfg.DATA.NUM_OUTPUTS\n",
    "    num_total_outputs = num_outputs*num_tasks\n",
    "    arr_metrics = np.zeros((3,1+num_total_outputs)) #row:mae, r2, avg_std; col: total mean, task1(output1), task2(output2),...\n",
    "\n",
    "    print('number of tasks that are being compared: ',num_total_outputs)\n",
    "\n",
    "    best_idx = np.argmin(mean_arr_cv_mae[1,:])\n",
    "    #best_idx = np.argmax(mean_arr_cv_r2[1,:])\n",
    "\n",
    "    print('best_idx',best_idx)\n",
    "    print('best combinations: ',combs[best_idx])\n",
    "\n",
    "    arr_metrics[0,0] = np.min(mean_arr_cv_mae[1,:])\n",
    "    arr_metrics[1,0] = np.max(mean_arr_cv_r2[1,:])\n",
    "    arr_metrics[2,0] = mean_arr_cv_err[1,best_idx]\n",
    "\n",
    "    print('best mean mae %.3f' % arr_metrics[0,0])\n",
    "    print('best mean r2 %.3f' % arr_metrics[1,0])\n",
    "    print('best mean err %.3f' % arr_metrics[2,0])\n",
    "    \n",
    "    cols_target_new = ['total']\n",
    "    for task_ind in range(num_tasks):\n",
    "        for out_ind in range(num_outputs):\n",
    "            j = out_ind + num_outputs*task_ind\n",
    "    #for j in range(num_total_outputs):\n",
    "            j_name = 'Task_'+str(task_ind+1) + '_Output_'+str(out_ind+1)\n",
    "            cols_target_new.append(j_name)\n",
    "            arr_metrics[0,j+1] = ls_arr_cv_mae[j][1,best_idx]\n",
    "            arr_metrics[1,j+1] = ls_arr_cv_r2[j][1,best_idx]\n",
    "            arr_metrics[2,j+1] = ls_arr_cv_err[j][1,best_idx]\n",
    "            print('best mae of target %d is %.3f' %(j,ls_arr_cv_mae[j][1,best_idx]))\n",
    "            print('best r2 of target %d is %.3f' %(j,ls_arr_cv_r2[j][1,best_idx]))\n",
    "            print('best err of target %d is %.3f' % (j,ls_arr_cv_err[j][1,best_idx]))\n",
    "    \n",
    "    df_test_metrics = pd.DataFrame(np.round(arr_metrics,3),columns = cols_target_new, \n",
    "                               index = [cfg.MODEL.METRIC,'R2','AVG_STD'])\n",
    "    print(df_test_metrics)\n",
    "    \n",
    "    #output_path = '/'.join([cfg.PATH.RESULT,cfg.MISC.DATA_NAME,cfg.MODEL.MODEL_NAME,cfg.MODEL.SPLIT,cfg.MISC.DATE])\n",
    "    df_test_metrics.to_csv(setup_data.output_path+'/df_test_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MO Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "mo_cv_trainer = CV_Trainer(cfg,ls_X_train,ls_X_test,ls_y_train,ls_y_test,obj_y_scaler)\n",
    "combs,ls_model_from_combs,ls_arr_cv_mae,ls_arr_cv_r2,ls_arr_cv_err,mean_arr_cv_mae,mean_arr_cv_r2,mean_arr_cv_err = mo_cv_trainer.set_up_cv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both targets\n",
      "best_idx 4\n",
      "mean min mae 0.430\n",
      "mean max r2 0.462\n",
      "mean min err 1.343\n",
      "min mae of target 0 is 0.436\n",
      "max r2 of target 0 is 0.625\n",
      "min err of target 0 is 1.387\n",
      "min mae of target 1 is 0.549\n",
      "max r2 of target 1 is 0.352\n",
      "min err of target 1 is 1.766\n",
      "(0.35, 700)\n"
     ]
    }
   ],
   "source": [
    "print('both targets')\n",
    "best_idx = np.argmin(mean_arr_cv_mae[1,:])\n",
    "\n",
    "print('best_idx',best_idx)\n",
    "print('mean min mae %.3f' %(np.min(mean_arr_cv_mae[1,:])))\n",
    "\n",
    "best_idx = np.argmax(mean_arr_cv_r2[1,:])\n",
    "#print('best_idx',best_idx)\n",
    "print('mean max r2 %.3f' %(np.max(mean_arr_cv_r2[1,:])))\n",
    "print('mean min err %.3f' %(mean_arr_cv_err[1,best_idx]))\n",
    "\n",
    "for j in range(cfg.DATA.NUM_OUTPUTS):\n",
    "    print('min mae of target %d is %.3f' %(j, ls_arr_cv_mae[j][1,best_idx]))\n",
    "#print('min mae target 1',ls_arr_cv_mae[1][1,best_idx])\n",
    "\n",
    "    print('max r2 of target %d is %.3f' %(j,ls_arr_cv_r2[j][1,best_idx]))\n",
    "#print('max r2 target 1',arr_cv_r2_1[1,best_idx])\n",
    "\n",
    "    print('min err of target %d is %.3f' %(j,ls_arr_cv_err[j][1,best_idx]))\n",
    "#print('min err target 1',arr_cv_err_1[1,best_idx])\n",
    "\n",
    "print(combs[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tasks that are being compared:  6\n",
      "best_idx 2\n",
      "best combinations:  (0.25, 900)\n",
      "best mean mae 0.599\n",
      "best mean r2 0.335\n",
      "best mean err 1.346\n",
      "best mae of target 0 is 0.658\n",
      "best r2 of target 0 is -0.443\n",
      "best err of target 0 is 1.300\n",
      "best mae of target 1 is 0.740\n",
      "best r2 of target 1 is 0.056\n",
      "best err of target 1 is 1.609\n",
      "best mae of target 2 is 0.255\n",
      "best r2 of target 2 is 0.367\n",
      "best err of target 2 is 0.588\n",
      "best mae of target 3 is 0.352\n",
      "best r2 of target 3 is 0.298\n",
      "best err of target 3 is 0.860\n",
      "best mae of target 4 is 0.601\n",
      "best r2 of target 4 is 0.545\n",
      "best err of target 4 is 1.165\n",
      "best mae of target 5 is 0.988\n",
      "best r2 of target 5 is 0.442\n",
      "best err of target 5 is 2.553\n",
      "         total  Task_1_Output_1  Task_1_Output_2  Task_2_Output_1  \\\n",
      "RMSE     0.599            0.658            0.740            0.255   \n",
      "R2       0.335           -0.443            0.056            0.367   \n",
      "AVG_STD  1.346            1.300            1.609            0.588   \n",
      "\n",
      "         Task_2_Output_2  Task_3_Output_1  Task_3_Output_2  \n",
      "RMSE               0.352            0.601            0.988  \n",
      "R2                 0.298            0.545            0.442  \n",
      "AVG_STD            0.860            1.165            2.553  \n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    if cfg.MODEL.SPLIT == 'by-task':\n",
    "        num_tasks = cfg.DATA.NUM_TASKS\n",
    "    else:\n",
    "        num_tasks = 1\n",
    "    \n",
    "    #num_tasks = cfg.DATA.NUM_TASKS\n",
    "    num_outputs = cfg.DATA.NUM_OUTPUTS\n",
    "    num_total_outputs = num_outputs*num_tasks\n",
    "    arr_metrics = np.zeros((3,1+num_total_outputs)) #row:mae, r2, avg_std; col: total mean, task1(output1), task2(output2),...\n",
    "\n",
    "    print('number of tasks that are being compared: ',num_total_outputs)\n",
    "\n",
    "    best_idx = np.argmin(mean_arr_cv_mae[1,:])\n",
    "    #best_idx = np.argmax(mean_arr_cv_r2[1,:])\n",
    "\n",
    "    print('best_idx',best_idx)\n",
    "    print('best combinations: ',combs[best_idx])\n",
    "\n",
    "    arr_metrics[0,0] = np.min(mean_arr_cv_mae[1,:])\n",
    "    arr_metrics[1,0] = np.max(mean_arr_cv_r2[1,:])\n",
    "    arr_metrics[2,0] = mean_arr_cv_err[1,best_idx]\n",
    "\n",
    "    print('best mean mae %.3f' % arr_metrics[0,0])\n",
    "    print('best mean r2 %.3f' % arr_metrics[1,0])\n",
    "    print('best mean err %.3f' % arr_metrics[2,0])\n",
    "        \n",
    "    cols_target_new = ['total']\n",
    "    for task_ind in range(num_tasks):\n",
    "        for out_ind in range(num_outputs):\n",
    "            j = out_ind + num_outputs*task_ind\n",
    "    #for j in range(num_total_outputs):\n",
    "            j_name = 'Task_'+str(task_ind+1) + '_Output_'+str(out_ind+1)\n",
    "            cols_target_new.append(j_name)\n",
    "            arr_metrics[0,j+1] = ls_arr_cv_mae[j][1,best_idx]\n",
    "            arr_metrics[1,j+1] = ls_arr_cv_r2[j][1,best_idx]\n",
    "            arr_metrics[2,j+1] = ls_arr_cv_err[j][1,best_idx]\n",
    "            print('best mae of target %d is %.3f' %(j,ls_arr_cv_mae[j][1,best_idx]))\n",
    "            print('best r2 of target %d is %.3f' %(j,ls_arr_cv_r2[j][1,best_idx]))\n",
    "            print('best err of target %d is %.3f' % (j,ls_arr_cv_err[j][1,best_idx]))\n",
    "    \n",
    "    df_test_metrics = pd.DataFrame(np.round(arr_metrics,3),columns = cols_target_new, \n",
    "                               index = [cfg.MODEL.METRIC,'R2','AVG_STD'])\n",
    "    print(df_test_metrics)\n",
    "    \n",
    "    df_test_metrics.to_csv(setup_data.output_path+'/df_test_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTMO Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tasks that are being compared:  4\n",
      "best_idx 7\n",
      "best combinations:  (0.15, 1100)\n",
      "best mean mae 0.502\n",
      "best mean r2 0.578\n",
      "best mean err 0.879\n",
      "best mae of target 0 is 0.363\n",
      "best r2 of target 0 is 0.616\n",
      "best err of target 0 is 0.612\n",
      "best mae of target 1 is 0.517\n",
      "best r2 of target 1 is 0.483\n",
      "best err of target 1 is 1.142\n",
      "best mae of target 2 is 0.368\n",
      "best r2 of target 2 is 0.789\n",
      "best err of target 2 is 0.609\n",
      "best mae of target 3 is 0.759\n",
      "best r2 of target 3 is 0.422\n",
      "best err of target 3 is 1.151\n",
      "         total  Task_1_Output_1  Task_1_Output_2  Task_2_Output_1  \\\n",
      "RMSE     0.502            0.363            0.517            0.368   \n",
      "R2       0.578            0.616            0.483            0.789   \n",
      "AVG_STD  0.879            0.612            1.142            0.609   \n",
      "\n",
      "         Task_2_Output_2  \n",
      "RMSE               0.759  \n",
      "R2                 0.422  \n",
      "AVG_STD            1.151  \n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    mtmo_cv_trainer = CV_Trainer(cfg,ls_X_train,ls_X_test,ls_y_train,ls_y_test,obj_y_scaler)\n",
    "    combs,ls_model_from_combs,ls_arr_cv_mae,ls_arr_cv_r2,ls_arr_cv_err,mean_arr_cv_mae,mean_arr_cv_r2,mean_arr_cv_err = mtmo_cv_trainer.set_up_cv_model()\n",
    "\n",
    "    if cfg.MODEL.SPLIT == 'by-task':\n",
    "        num_tasks = cfg.DATA.NUM_TASKS\n",
    "    else:\n",
    "        num_tasks = 1\n",
    "    num_outputs = cfg.DATA.NUM_OUTPUTS\n",
    "    num_total_outputs = num_outputs*num_tasks\n",
    "    arr_metrics = np.zeros((3,1+num_total_outputs)) #row:mae, r2, avg_std; col: total mean, task1(output1), task2(output2),...\n",
    "\n",
    "    print('number of tasks that are being compared: ',num_total_outputs)\n",
    "\n",
    "    best_idx = np.argmin(mean_arr_cv_mae[1,:])\n",
    "    #best_idx = np.argmax(mean_arr_cv_r2[1,:])\n",
    "\n",
    "    print('best_idx',best_idx)\n",
    "    print('best combinations: ',combs[best_idx])\n",
    "\n",
    "    arr_metrics[0,0] = np.min(mean_arr_cv_mae[1,:])\n",
    "    arr_metrics[1,0] = np.max(mean_arr_cv_r2[1,:])\n",
    "    arr_metrics[2,0] = mean_arr_cv_err[1,best_idx]\n",
    "\n",
    "    print('best mean mae %.3f' % arr_metrics[0,0])\n",
    "    print('best mean r2 %.3f' % arr_metrics[1,0])\n",
    "    print('best mean err %.3f' % arr_metrics[2,0])\n",
    "    \n",
    "    cols_target_new = ['total']\n",
    "    #for j in range(cfg.DATA.NUM_OUTPUTS):\n",
    "    for task_ind in range(num_tasks):\n",
    "        for out_ind in range(num_outputs):\n",
    "            j = out_ind + num_outputs*task_ind\n",
    "            j_name = 'Task_'+str(task_ind+1) + '_Output_'+str(out_ind+1)\n",
    "            cols_target_new.append(j_name)\n",
    "            arr_metrics[0,j+1] = ls_arr_cv_mae[j][1,best_idx]\n",
    "            arr_metrics[1,j+1] = ls_arr_cv_r2[j][1,best_idx]\n",
    "            arr_metrics[2,j+1] = ls_arr_cv_err[j][1,best_idx]\n",
    "            print('best mae of target %d is %.3f' %(j,ls_arr_cv_mae[j][1,best_idx]))\n",
    "            print('best r2 of target %d is %.3f' %(j,ls_arr_cv_r2[j][1,best_idx]))\n",
    "            print('best err of target %d is %.3f' % (j,ls_arr_cv_err[j][1,best_idx]))\n",
    "    \n",
    "    df_test_metrics = pd.DataFrame(np.round(arr_metrics,3),columns = cols_target_new, \n",
    "                               index = [cfg.MODEL.METRIC,'R2','AVG_STD'])\n",
    "    print(df_test_metrics)\n",
    "    \n",
    "    output_path = '/'.join([cfg.PATH.RESULT,cfg.MISC.DATA_NAME,cfg.MODEL.MODEL_NAME,cfg.MODEL.SPLIT,cfg.MISC.DATE,'num_tasks_'+str(cfg.DATA.NUM_TASKS)])\n",
    "    df_test_metrics.to_csv(output_path+'/df_test_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTMO-LMGP CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 102.0740: 100%|██████████| 100/100 [00:01<00:00, 91.62it/s] \n",
      "Epoch 99 - loss 73.5903: 100%|██████████| 100/100 [00:00<00:00, 114.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 56.5818: 100%|██████████| 100/100 [00:01<00:00, 91.97it/s]\n",
      "Epoch 99 - loss 48.7822: 100%|██████████| 100/100 [00:01<00:00, 77.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 53.5382: 100%|██████████| 100/100 [00:01<00:00, 63.13it/s]\n",
      "Epoch 99 - loss 41.9380: 100%|██████████| 100/100 [00:01<00:00, 56.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 58.0313: 100%|██████████| 100/100 [00:02<00:00, 47.08it/s]\n",
      "Epoch 99 - loss 51.6604: 100%|██████████| 100/100 [00:02<00:00, 43.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 57.0702: 100%|██████████| 100/100 [00:02<00:00, 37.74it/s]\n",
      "Epoch 99 - loss 49.3615: 100%|██████████| 100/100 [00:02<00:00, 36.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 70.3143: 100%|██████████| 100/100 [00:03<00:00, 33.07it/s]\n",
      "Epoch 99 - loss 47.0913: 100%|██████████| 100/100 [00:03<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 48.4372: 100%|██████████| 100/100 [00:03<00:00, 27.20it/s]\n",
      "Epoch 99 - loss 47.8960: 100%|██████████| 100/100 [00:04<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 40.3155: 100%|██████████| 100/100 [00:04<00:00, 22.06it/s]\n",
      "Epoch 99 - loss 40.1384: 100%|██████████| 100/100 [00:04<00:00, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 50.7406: 100%|██████████| 100/100 [00:05<00:00, 17.47it/s]\n",
      "Epoch 99 - loss 50.5956: 100%|██████████| 100/100 [00:05<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "## Learning the model's parameters has started ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 - loss 48.9810: 100%|██████████| 100/100 [00:06<00:00, 16.06it/s]\n",
      "Epoch 99 - loss 48.8303: 100%|██████████| 100/100 [00:06<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Learning the model's parameters is successfully finished ##\n",
      "number of tasks that are being compared:  6\n",
      "best_idx 1\n",
      "best combinations:  (0.02, 100)\n",
      "best mean mae 0.574\n",
      "best mean r2 -2.198\n",
      "best mean err 1.334\n",
      "best mae of target 0 is 0.634\n",
      "best r2 of target 0 is -3.551\n",
      "best err of target 0 is 1.281\n",
      "best mae of target 1 is 0.736\n",
      "best r2 of target 1 is -5.201\n",
      "best err of target 1 is 1.440\n",
      "best mae of target 2 is 0.286\n",
      "best r2 of target 2 is -0.716\n",
      "best err of target 2 is 1.195\n",
      "best mae of target 3 is 0.352\n",
      "best r2 of target 3 is -0.255\n",
      "best err of target 3 is 1.328\n",
      "best mae of target 4 is 0.666\n",
      "best r2 of target 4 is -0.858\n",
      "best err of target 4 is 1.302\n",
      "best mae of target 5 is 0.772\n",
      "best r2 of target 5 is -2.608\n",
      "best err of target 5 is 1.461\n",
      "         total  Task_1_Output_1  Task_1_Output_2  Task_2_Output_1  \\\n",
      "MAE      0.574            0.634            0.736            0.286   \n",
      "R2      -2.198           -3.551           -5.201           -0.716   \n",
      "AVG_STD  1.334            1.281            1.440            1.195   \n",
      "\n",
      "         Task_2_Output_2  Task_3_Output_1  Task_3_Output_2  \n",
      "MAE                0.352            0.666            0.772  \n",
      "R2                -0.255           -0.858           -2.608  \n",
      "AVG_STD            1.328            1.302            1.461  \n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    mtmolmgp_cv_trainer = CV_Trainer(cfg,ls_X_train,ls_X_test,ls_y_train,ls_y_test,obj_y_scaler)\n",
    "    combs,ls_model_from_combs,ls_arr_cv_mae,ls_arr_cv_r2,ls_arr_cv_err,mean_arr_cv_mae,mean_arr_cv_r2,mean_arr_cv_err = mtmolmgp_cv_trainer.set_up_cv_model()\n",
    "\n",
    "    if cfg.MODEL.SPLIT == 'by-task':\n",
    "        num_tasks = cfg.DATA.NUM_TASKS\n",
    "    else:\n",
    "        num_tasks = 1\n",
    "    num_outputs = cfg.DATA.NUM_OUTPUTS\n",
    "    num_total_outputs = num_outputs*num_tasks\n",
    "    arr_metrics = np.zeros((3,1+num_total_outputs)) #row:mae, r2, avg_std; col: total mean, task1(output1), task2(output2),...\n",
    "\n",
    "    print('number of tasks that are being compared: ',num_total_outputs)\n",
    "\n",
    "    best_idx = np.argmin(mean_arr_cv_mae[1,:])\n",
    "    #best_idx = np.argmax(mean_arr_cv_r2[1,:])\n",
    "\n",
    "    print('best_idx',best_idx)\n",
    "    print('best combinations: ',combs[best_idx])\n",
    "\n",
    "    arr_metrics[0,0] = np.min(mean_arr_cv_mae[1,:])\n",
    "    arr_metrics[1,0] = np.max(mean_arr_cv_r2[1,:])\n",
    "    arr_metrics[2,0] = mean_arr_cv_err[1,best_idx]\n",
    "\n",
    "    print('best mean mae %.3f' % arr_metrics[0,0])\n",
    "    print('best mean r2 %.3f' % arr_metrics[1,0])\n",
    "    print('best mean err %.3f' % arr_metrics[2,0])\n",
    "    \n",
    "    cols_target_new = ['total']\n",
    "    #for j in range(cfg.DATA.NUM_OUTPUTS):\n",
    "    for task_ind in range(num_tasks):\n",
    "        for out_ind in range(num_outputs):\n",
    "            j = out_ind + num_outputs*task_ind\n",
    "            j_name = 'Task_'+str(task_ind+1) + '_Output_'+str(out_ind+1)\n",
    "            cols_target_new.append(j_name)\n",
    "            arr_metrics[0,j+1] = ls_arr_cv_mae[j][1,best_idx]\n",
    "            arr_metrics[1,j+1] = ls_arr_cv_r2[j][1,best_idx]\n",
    "            arr_metrics[2,j+1] = ls_arr_cv_err[j][1,best_idx]\n",
    "            print('best mae of target %d is %.3f' %(j,ls_arr_cv_mae[j][1,best_idx]))\n",
    "            print('best r2 of target %d is %.3f' %(j,ls_arr_cv_r2[j][1,best_idx]))\n",
    "            print('best err of target %d is %.3f' % (j,ls_arr_cv_err[j][1,best_idx]))\n",
    "    \n",
    "    df_test_metrics = pd.DataFrame(np.round(arr_metrics,3),columns = cols_target_new, \n",
    "                               index = ['MAE','R2','AVG_STD'])\n",
    "    print(df_test_metrics)\n",
    "    \n",
    "    output_path = '/'.join([cfg.PATH.RESULT,cfg.MISC.DATA_NAME,cfg.MODEL.MODEL_NAME,cfg.MODEL.SPLIT,cfg.MISC.DATE,'num_tasks_'+str(cfg.DATA.NUM_TASKS)])\n",
    "    df_test_metrics.to_csv(output_path+'/df_test_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-gp-mac-no-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
