{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import factorize\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "os.chdir('/Users/chenya68/Documents/GitHub/BFO')\n",
    "df_x = pd.read_excel('data/harpoon-doe.xlsx',sheet_name = 0, usecols = [1,2,3,4])\n",
    "df_x.columns = [re.sub('[^A-Za-z0-9Δ]+', '_', element) for element in df_x.columns]\n",
    "#print(len(df_x))\n",
    "#df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_1 = pd.read_excel('data/harpoon-doe.xlsx',sheet_name = 1, usecols = [1,4,7],skiprows = lambda x: x in [1])\n",
    "df_y_1.columns = [re.sub('[^A-Za-z0-9Δ]+', '_', element) for element in df_y_1.columns]\n",
    "#print(len(df_y_1))\n",
    "#print(df_y_1.head())\n",
    "\n",
    "df_y_2 = pd.read_excel('data/harpoon-doe.xlsx',sheet_name = 1, usecols = [2,5,8],skiprows = lambda x: x in [1])\n",
    "df_y_2.columns = df_y_1.columns\n",
    "#print(len(df_y_2))\n",
    "#print(df_y_2.head())\n",
    "\n",
    "df_y_3 = pd.read_excel('data/harpoon-doe.xlsx',sheet_name = 1, usecols = [3,6,9],skiprows = lambda x: x in [1])\n",
    "df_y_3.columns = df_y_1.columns\n",
    "#print(len(df_y_3))\n",
    "#print(df_y_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_feature01 = list(df_x.columns)\n",
    "cols_target = list(df_y_1.columns)[0:2]\n",
    "#cols_target = list(df_y_1.columns)\n",
    "cols_cate = ['Buffer_Type',\n",
    " 'Sugar_Salt',\n",
    " 'Additive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Dimer_HMW_</th>\n",
       "      <th>_Monomer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>95.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>94.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.4</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.2</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.3</td>\n",
       "      <td>92.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3.7</td>\n",
       "      <td>92.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3.6</td>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4.2</td>\n",
       "      <td>90.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4.4</td>\n",
       "      <td>90.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _Dimer_HMW_  _Monomer\n",
       "0           2.4      95.1\n",
       "1           0.8      97.3\n",
       "2           3.2      94.3\n",
       "3           1.4      96.7\n",
       "4           4.2      93.3\n",
       "..          ...       ...\n",
       "67          3.3      92.3\n",
       "68          3.7      92.3\n",
       "69          3.6      92.2\n",
       "70          4.2      90.8\n",
       "71          4.4      90.3\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df_y_long = pd.concat((df_y_1[cols_target],df_y_2[cols_target],df_y_3[cols_target]),axis = 0)\n",
    "total_df_y_long.reset_index(inplace = True, drop = True)\n",
    "total_df_y_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_1.columns = [c+'_1' for c in df_y_1.columns]\n",
    "df_y_2.columns = [c+'_2' for c in df_y_2.columns]\n",
    "df_y_3.columns = [c+'_3' for c in df_y_3.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_target_new = ['_Dimer_HMW_1', '_Monomer_1',\n",
    "       '_Dimer_HMW_2', '_Monomer_2', \n",
    "       '_Dimer_HMW_3','_Monomer_3']\n",
    "\n",
    "arr_Y = np.concatenate((df_y_1.to_numpy()[:,:2],\n",
    "                            df_y_2.to_numpy()[:,:2],\n",
    "                            df_y_3.to_numpy()[:,:2]),axis = 1)\n",
    "total_df_y_wide = pd.DataFrame(arr_Y,columns= cols_target_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>Buffer_Type_label</th>\n",
       "      <th>Sugar_Salt_label</th>\n",
       "      <th>Additive_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pH  Buffer_Type_label  Sugar_Salt_label  Additive_label\n",
       "0  4.5                  0                 0               0\n",
       "1  4.5                  0                 0               1\n",
       "2  5.0                  0                 0               0\n",
       "3  5.0                  0                 0               1\n",
       "4  5.0                  0                 1               1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert categorical columns to labels\n",
    "for x_name in cols_cate:\n",
    "    labels, categories = factorize(df_x[x_name])\n",
    "    df_x[x_name+\"_label\"] = labels\n",
    "df_x.drop(cols_cate,axis = 1,inplace = True)\n",
    "display(df_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder output/recreate-gp/multi-task-multi-output-task_rank_3-output_rank_2-lik_rank_1-x-minmax-y-minmax-cate_transform_partial-LMGP-mix-stratify-x-noise_0.2\n"
     ]
    }
   ],
   "source": [
    "ls_model = ['simpleGP','multi-task-single-output','multi-task-multi-output','multi-task-multi-input-multi-output']\n",
    "ls_x_scale = ['no-x-scale','x-minmax','x-stand','x-robust']\n",
    "ls_y_scale = ['no-y-scale','y-minmax','y-stand','y-robust']\n",
    "ls_cate_transform = ['label','ohe','LVGP','full-LMGP','partial-LMGP']\n",
    "ls_remove_pred_outlier = [0,1]\n",
    "ls_output_rank_option = [1,2]\n",
    "ls_task_rank_option = [1,2,3,4,5,6,7]\n",
    "ls_lik_rank_option = [0,1,2]\n",
    "ls_split_option = ['mix','separate'] #mix: combine all tasks first then do train, test split (could stratify task?) #separate, do train-test-split first, then combine tasks\n",
    "ls_stratify_task = ['not-stratify','stratify-x','stratify-y','stratify-xy']\n",
    "\n",
    "\n",
    "model_option = 'multi-task-multi-output'\n",
    "x_scale_option = 'x-minmax'\n",
    "y_scale_option = 'y-minmax'\n",
    "cate_transform_option = 'partial-LMGP'\n",
    "#remove_pred_outlier_option= 0\n",
    "\n",
    "output_rank_option = 2 #if 0, no correlation between output\n",
    "task_rank_option = 3#if 0, no correlation between tasks\n",
    "lik_rank_option = 1\n",
    "split_option = 'mix'\n",
    "stratify_option = 'stratify-x'\n",
    "\n",
    "noise_option = 0.2 #noise percentage\n",
    "\n",
    "model_label = model_option\n",
    "x_scale_label = x_scale_option\n",
    "y_scale_label = y_scale_option\n",
    "cate_transform_label = 'cate_transform_'+cate_transform_option\n",
    "#remove_pred_outlier_label = 'remove_pred_outlier_'+str(remove_pred_outlier_option)\n",
    "output_rank_label = 'output_rank_'+str(output_rank_option)\n",
    "task_rank_label = 'task_rank_'+str(task_rank_option)\n",
    "lik_rank_label = 'lik_rank_'+str(lik_rank_option)\n",
    "split_label = split_option\n",
    "stratify_label = stratify_option\n",
    "if noise_option>0:\n",
    "        noise_label = 'noise_'+str(noise_option)\n",
    "else:\n",
    "        noise_label = ''\n",
    "\n",
    "folder_name = '-'.join([model_label,task_rank_label,output_rank_label,lik_rank_label,x_scale_label,y_scale_label,cate_transform_label,\n",
    "                        split_label,stratify_label,noise_label])\n",
    "\n",
    "figPath = 'output/recreate-gp/'+folder_name\n",
    "if not os.path.exists(figPath):\n",
    "        print(f'Creating folder {figPath}')\n",
    "        os.makedirs(figPath,exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_label = 'mix'\n",
    "if split_label == 'mix':\n",
    "    ls_X = [df_x.copy(),\n",
    "            df_x.copy(),\n",
    "            df_x.copy()]\n",
    "    \n",
    "    for i,tmp_df_x in enumerate(ls_X):\n",
    "        tmp_df_x['task_ind'] = i\n",
    "\n",
    "    df_X = pd.concat(ls_X)\n",
    "    df_X.reset_index(inplace=True, drop = True)\n",
    "    #print(df_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "N = len(df_X)\n",
    "#percentage = 0.05\n",
    "if noise_option>0:\n",
    "#create data with noise\n",
    "    df_X_syn = df_X.copy()\n",
    "    for col in df_X.columns.difference(['task_ind']):\n",
    "        df_X_syn[col] = df_X_syn[col] + np.random.normal(0, df_X_syn[col].std(), N) * noise_option\n",
    "\n",
    "    df_Y_syn= total_df_y_long[cols_target].copy()\n",
    "    for col in cols_target:\n",
    "        df_Y_syn[col] = df_Y_syn[col] + np.random.normal(0, df_Y_syn[col].std(), N) * noise_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_task_label = 'hier'\n",
    "#cols_feature_new = df_x.columns\n",
    "\n",
    "if noise_option>0:\n",
    "    df_total_X = pd.concat((df_X,df_X_syn))\n",
    "    df_total_Y = pd.concat((total_df_y_long[cols_target],df_Y_syn))\n",
    "else:\n",
    "    df_total_X = df_X\n",
    "    df_total_Y = total_df_y_long\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "ls_n_clusters = [4,2,2]\n",
    "for i,x_name in enumerate(['Buffer_Type_label','Sugar_Salt_label','Additive_label']):\n",
    "    best_n_clusters = ls_n_clusters[i]\n",
    "    km = KMeans(n_clusters=best_n_clusters, random_state=10)\n",
    "    kmeans = km.fit(df_total_X[[x_name]])\n",
    "    df_total_X[x_name] = kmeans.labels_\n",
    "\n",
    "if multi_task_label == 'hier':\n",
    "    df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df_total_X, df_total_Y, test_size=0.2, \n",
    "                                                                random_state=0, \n",
    "                                                                stratify=df_total_X['task_ind'])\n",
    "\n",
    "else:\n",
    "    df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df_total_X, df_total_Y, test_size=0.2, \n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "xct = ColumnTransformer([('x_mm_scaler',MinMaxScaler(),\n",
    "                          df_X_train.columns.difference(['Buffer_Type_label','Sugar_Salt_label','Additive_label','task_ind']))], \n",
    "                         remainder = 'passthrough')\n",
    "\n",
    "scaled_X_train=xct.fit_transform(df_X_train) \n",
    "scaled_X_test=xct.transform(df_X_test)\n",
    "\n",
    "t_train_x = torch.Tensor(scaled_X_train)\n",
    "t_test_x = torch.Tensor(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_ind_lev = {1: 4, 2:2, 3:2}\n",
    "quant_index = [0]\n",
    "task_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_scale_label = 'y-stand'\n",
    "y_scale_label = 'y-minmax'\n",
    "\n",
    "scaled_y_train = np.zeros_like(df_y_train.to_numpy())\n",
    "scaled_y_test = np.zeros_like(df_y_test.to_numpy())\n",
    "ls_y_task_scaler = []\n",
    "ls_row_idx_train = []\n",
    "ls_row_idx_test = []\n",
    "#if y_scale_option==1:\n",
    "if y_scale_label == 'y-robust':\n",
    "    y_scaler = RobustScaler()\n",
    "    scaled_y_train = y_scaler.fit_transform(df_y_train)\n",
    "    scaled_y_test= y_scaler.transform(df_y_test)\n",
    "elif y_scale_label == 'y-stand':\n",
    "    #y_scaler = StandardScaler()\n",
    "    #scaled_y_train = y_scaler.fit_transform(df_y_train)\n",
    "    #scaled_y_test= y_scaler.transform(df_y_test)\n",
    "    for task_ind in range(3):\n",
    "        y_task_scaler = StandardScaler()\n",
    "        row_idx_train = np.where(df_X_train['task_ind']==task_ind)[0]\n",
    "        ls_row_idx_train.append(row_idx_train)\n",
    "        row_idx_test = np.where(df_X_test['task_ind']==task_ind)[0]\n",
    "        ls_row_idx_test.append(row_idx_test)\n",
    "        scaled_y_train_task =y_task_scaler.fit_transform(df_y_train[df_X_train['task_ind']==task_ind])\n",
    "        scaled_y_test_task= y_task_scaler.transform(df_y_test[df_X_test['task_ind']==task_ind])\n",
    "        ls_y_task_scaler.append(y_task_scaler)\n",
    "        scaled_y_train[row_idx_train] = scaled_y_train_task\n",
    "        scaled_y_test[row_idx_test] = scaled_y_test_task\n",
    "elif y_scale_label == 'y-minmax':\n",
    "    y_scaler = MinMaxScaler()\n",
    "    scaled_y_train = y_scaler.fit_transform(df_y_train)\n",
    "    scaled_y_test= y_scaler.transform(df_y_test)\n",
    "else:\n",
    "    scaled_y_train = df_y_train.to_numpy()\n",
    "    scaled_y_test = df_y_test.to_numpy()\n",
    "\n",
    "t_train_y = torch.Tensor(scaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "#from gpplus import kernels\n",
    "#from gpplus.priors import LogHalfHorseshoePrior,MollifiedUniformPrior\n",
    "from gpytorch.priors import NormalPrior,LogNormalPrior\n",
    "from gpytorch.constraints import GreaterThan,Positive\n",
    "\n",
    "class MultiOutputMultiTaskGP(gpytorch.models.ExactGP):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        data_kernel,\n",
    "        noise_indices,\n",
    "        fix_noise:bool=False,\n",
    "        lb_noise:float=1e-4,\n",
    "        task_rank = None,\n",
    "        output_rank = None,\n",
    "        lik_rank = None\n",
    "    ) -> None:\n",
    "\n",
    "        num_outputs = train_Y.shape[-1]\n",
    "        num_tasks = len(torch.unique(train_X[..., -1]))\n",
    "        self._num_tasks = num_tasks\n",
    "        self._num_outputs = num_outputs\n",
    "        \n",
    "        self.task_rank = task_rank if task_rank is not None else num_tasks\n",
    "        self.output_rank = output_rank if output_rank is not None else num_outputs\n",
    "        self.lik_rank = lik_rank if lik_rank is not None else 0\n",
    "        # initializing likelihood\n",
    "        likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_outputs,rank = self.lik_rank)\n",
    "        super(MultiOutputMultiTaskGP, self).__init__(train_X, train_Y,likelihood)\n",
    "\n",
    "        self.likelihood.register_prior('raw_noise_prior',LogHalfHorseshoePrior(0.01,lb_noise),'raw_noise')\n",
    "        if self.lik_rank == 0:\n",
    "            self.likelihood.register_prior('raw_task_noises_prior',LogHalfHorseshoePrior(0.01,lb_noise),'raw_task_noises')    \n",
    "        else:\n",
    "            self.likelihood.register_prior('task_noise_covar_factor_prior',NormalPrior(0.,1),'task_noise_covar_factor')\n",
    "\n",
    "        #self.likelihood.register_prior('raw_task_noises_prior',LogHalfHorseshoePrior(0.01,lb_noise),'raw_task_noises')\n",
    "        #self.likelihood.register_prior('raw_noise_prior',LogHalfHorseshoePrior(0.01,lb_noise),'raw_noise')\n",
    "        if fix_noise:\n",
    "            self.likelihood.raw_noise.requires_grad_(False)\n",
    "            self.likelihood.noise_covar.noise =torch.tensor(4.9901e-05)\n",
    "\n",
    "        \n",
    "        #define prior for mean module\n",
    "        mean_list = [gpytorch.means.ConstantMean(NormalPrior(0,1)) for t in range(num_outputs)]\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            mean_list, num_tasks=num_outputs\n",
    "        )\n",
    "        \n",
    "        self.data_kernel = data_kernel\n",
    "        if isinstance(data_kernel,str):\n",
    "            try:\n",
    "                data_kernel_class = getattr(kernels,data_kernel)\n",
    "                self.data_kernel = data_kernel_class(\n",
    "                    ard_num_dims = self.train_inputs[0].size(1),\n",
    "                    lengthscale_constraint=Positive(transform=torch.exp,inv_transform=torch.log),\n",
    "                )\n",
    "                \n",
    "                self.data_kernel.register_prior(\n",
    "                    'lengthscale_prior',MollifiedUniformPrior(math.log(0.1),math.log(10)),'raw_lengthscale'\n",
    "                )\n",
    "                \n",
    "            except:\n",
    "                raise RuntimeError(\n",
    "                    \"%s not an allowed kernel\" % data_kernel\n",
    "                )\n",
    "        \n",
    "        elif not isinstance(data_kernel,gpytorch.kernels.Kernel):\n",
    "            raise RuntimeError(\n",
    "                \"specified data kernel is not a `gpytorch.kernels.Kernel` instance\"\n",
    "            )\n",
    "\n",
    "        #define kernel for gplvm on mixed variables\n",
    "        self.data_kernel2 = gpytorch.kernels.RBFKernel()\n",
    "        self.data_kernel2.register_prior(\n",
    "                    'lengthscale_prior',MollifiedUniformPrior(math.log(0.1),math.log(10)),'raw_lengthscale'\n",
    "                )\n",
    "\n",
    "        self.task_kernel = gpytorch.kernels.IndexKernel(num_tasks=num_tasks, rank = self.task_rank) #default rank is 1\n",
    "        self.output_kernel = gpytorch.kernels.IndexKernel(num_tasks=num_outputs, rank = self.output_rank) #default rank is 1\n",
    "        \n",
    "        self.task_kernel.register_prior(\"covar_factor_prior\",NormalPrior(0.,1),lambda m: m._parameters['covar_factor'])\n",
    "        self.task_kernel.register_prior(\"raw_var_prior\",NormalPrior(0.,1),lambda m: m._parameters['raw_var'])\n",
    "\n",
    "        self.output_kernel.register_prior(\"covar_factor_prior\",NormalPrior(0.,1),lambda m: m._parameters['covar_factor'])\n",
    "        self.output_kernel.register_prior(\"raw_var_prior\",NormalPrior(0.,1),lambda m: m._parameters['raw_var'])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        task_term = self.task_kernel(x[..., -1].long())\n",
    "        data_and_task_x = self.data_kernel(x[..., :-1]).mul(task_term)\n",
    "        output_x = self.output_kernel.covar_matrix\n",
    "        covar_x = gpytorch.lazy.KroneckerProductLazyTensor(data_and_task_x, output_x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    def predict(\n",
    "        self,x:torch.Tensor,return_std:bool=False,include_noise:bool=False\n",
    "    ):\n",
    "\n",
    "        self.eval()\n",
    "        self.likelihood.eval()\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            pred_res = self.likelihood(self.forward(x))   \n",
    "            mean = pred_res.mean\n",
    "            lower, upper = pred_res.confidence_region()\n",
    "        return mean, lower, upper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-gp-mac-no-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
